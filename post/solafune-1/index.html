<!doctype html><html lang=en><head><title>Solafune コンペ#1に参加しました | Ikath Tech Blog</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=keywords content="Ikath Tech Blog"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="solafune コンペ#1に参加しました"><meta property="og:description" content="cf. @solafune (https://solafune.com)
solafune 主催のコンテスト#1 に参加しました。このコンテストで私がどのようなアプローチをとり、結果に対してどう考察したのかを紹介します。ちなみに、コンテストの結果は 8/118人 でした。本記事は参加していないとイマ …"><meta property="og:url" content="https://s-kaisei.github.io/Ikath-Tech-Blog/post/solafune-1/"><meta property="og:image" content="images/%!s()"><link rel=apple-touch-icon sizes=180x180 href=https://s-kaisei.github.io/Ikath-Tech-Blog/images/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://s-kaisei.github.io/Ikath-Tech-Blog/images/icons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://s-kaisei.github.io/Ikath-Tech-Blog/images/icons/favicon-16x16.png><link rel=manifest href=https://s-kaisei.github.io/Ikath-Tech-Blog/images/icons/site.webmanifest><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><link rel=canonical href=https://s-kaisei.github.io/Ikath-Tech-Blog/post/solafune-1/><link rel=stylesheet href=https://s-kaisei.github.io/Ikath-Tech-Blog/css/styles.86c6da248e485cdc7f340baeb04c29cf0499e12a33a387104028f046c1d4ba15aa3ef8a4bf8f44a2fba7f0263053fa54dc4d2f2baa3d6c8ebb3c69f7bdbded2b.css integrity="sha512-hsbaJI5IXNx/NAuusEwpzwSZ4Sozo4cQQCjwRsHUuhWqPvikv49Eovun8CYwU/pU3E0vK6o9bI67PGn3vb3tKw=="></head><body><div class=nav-drop><div class=nav-body><a href=https://s-kaisei.github.io/Ikath-Tech-Blog/about/ class=nav_item>AboutMe</a>
<a href=https://s-kaisei.github.io/Ikath-Tech-Blog/post/ class=nav_item>Blog</a><div class=nav-close></div><div class=color_mode><label for=mode>Toggle Dark Mode</label>
<input type=checkbox class=color_choice id=mode></div></div></div><header class=nav><nav class=nav-menu><a href=https://s-kaisei.github.io/Ikath-Tech-Blog/ class="nav-brand nav_item">Ikath Tech Blog</a><div class=nav_bar-wrap><div class=nav_bar></div></div></nav></header><main><div class="wrap mt post"><div><p class=post_date>06. December 2020</p><h1 class=post_title>solafune コンペ#1に参加しました</h1><div class=post_body><div class=post_inner><p>cf. @solafune (<a href=https://solafune.com>https://solafune.com</a>)</p><p>solafune 主催のコンテスト#1 に参加しました。このコンテストで私がどのようなアプローチをとり、結果に対してどう考察したのかを紹介します。ちなみに、コンテストの結果は 8/118人 でした。本記事は参加していないとイマイチ理解し難い記事となっていることをご了承ください。(画像データ等が取り扱えないため)</p><p>　　　</p><h2 id=概要>概要</h2><p>衛生画像から空港利用者数を予測します。詳しくは<a href=https://solafune.com/#/competitions/ea90cba4-3e01-42df-9516-9ac0d7a44204>こちら</a>。</p><p>　　　</p><h2 id=始めにやったこと>始めにやったこと</h2><p>始めに、それぞれの衛生画像に対して空港利用者数がどれくらいなのかを確認して考察しました。ここで気づいたのが、以下の二つです。</p><p>・ 空港が大きければ、利用者数も多い。</p><p>・ 空港の立地によって利用者数が異なる。森林が多いと少なく、海岸近くなら多い。</p><p>この二つの特徴をうまく数値化して、回帰分析すれば良い結果が出ないかなと考えました。ただ、これを適用する前に一旦定番の転移学習・ファインチューニングを試してみることにしました。</p><p>　　　</p><h2 id=転移学習ファインチューニングアルファ>転移学習・ファインチューニング+アルファ</h2><p>基本的に多くの参加者が試したのではないでしょうか。画像があったら CNN の転移学習・ファインチューニングって感じですよね。私も実際に試してみました。最初は特に前処理・データ拡張等は行わず、ResNet と imagenet で事前に学習した重みを使って学習させました。結果としては、train data、validation data 共に誤差がとても大きく、テストとして一度提出してみるのも躊躇うレベルでした。ここで、なんで精度が悪かったのかを考えたとき、全体画像に対して空港が小さすぎるのが問題ではないかと考えました。なので、空港部分をクロップして新たなデータセットにすることにしました。幸いにも空港を中心として衛生写真が撮られていたので、中心から一定の大きさでクロップしました。ここでの結果は、クロップ前よりは精度が大幅に上がりましたが、いまいちパッとしない精度でした。一度テストとして提出してみましたが、スコアは 2.6 程度で当時では 20 位くらいでした。次に試したのは、事前学習させた重みを使わずにスクラッチで行ってみました。特徴抽出の仕方が一般的なのより異なっていたら精度に影響するかもしれないと考えたからです。すると、結果はそこそこ良くなり、テストデータに対しては、1.8 を記録しました。CNN に関するアプローチはここで終わりにしました。</p><p>​</p><h2 id=nn-による回帰分析>NN による回帰分析</h2><p>上の方にも書きましたが、空港の大きさと空港の立地を数値化して、説明変数として用いて回帰分析ができれば、精度が上がるのではないかと踏んでこちらを試してみることにしました。どのように数値化するのかが問題になってくるのですが、私はそれぞれ以下の方法を試してみることにしました。</p><p>・ セマンティックセグメンテーションによる空港の検出</p><p>・ エントロピー 計算による数値化</p><p>​</p><h4 id=セマンティックセグメンテーションによる空港の検出>セマンティックセグメンテーションによる空港の検出</h4><p>最初は画像処理技術をふんだんに使用して空港を検出しようと考えたのですが、白飛びしている画像等があり、なかなかうまくいきませんでした。なので、セマンティックセグメンテーションを使って空港を検出することにしました。セマンティックセグメンテーションの手法は DeepLabv3+ を使用しました。DeepLabv3 に関してなかなか独自のデータセットを使って学習する記事がなく、苦戦を強いられましたが、色々試行錯誤してなんとか学習まで行うことができました。validation data に対して検出を行ったところ、見た目ではあるのですが、かなり良い精度が出せていました。</p><p>​</p><h4 id=エントロピー計算による数値化>エントロピー計算による数値化</h4><p>エントロピーを使えば立地の数値化ができるのではないかと考えました。例えば、海のような同色の割合が多くある場所だとエントロピーは小さくなり、山や街並みが多く見える場所は複雑ゆえエントロピー値が大きくなります。</p><p>　　　</p><p>この２つの値を説明変数として使用して、回帰分析を行いました。最初中間層のノード数を何も考えず 64 にしていたのですが、そのときの結果は、転移学習・ファインチューニングしたときの結果とほぼ同等でした。インプットデータ数が2つなのに中間層のノード数が 64 でいいのか疑問に感じ、4 に変更して試したところ結果は以下のようになりました。</p><picture class=nav_logo>
<source srcset=https://s-kaisei.github.io/Ikath-Tech-Blog/images/solafune_result1.png media="(prefers-color-scheme: dark)"><img srcset=https://s-kaisei.github.io/Ikath-Tech-Blog/images/solafune_result1.png alt=solafune_result1></picture><p>　　　</p><h2 id=まとめ>まとめ</h2><p>データを把握してからどのようにアプローチするかを決めて、実行に移しました。今回は、CNN の転移学習・ファインチューニングと NN による回帰分析を試し、結果的には後者が精度がよく採用しました。NN による回帰分析の方はあまり考察ができず、結果を詰めれなかったのが少し悔いですが、自分なりに考えを出し結果まで出すことができたので良かったです。今後も積極的にコンテストに参加したいと思います。以上です。お疲れ様でした。</p><p>　　　</p></div><div class="post_extra mb-2"><div class=copy data-before="Share Story" data-after="Link Copied"><svg class="icon"><use xlink:href="#copy"/></svg></div></div><div></div></div></div><a href=https://s-kaisei.github.io/Ikath-Tech-Blog/ class=post_nav><span class=post_next>The Latest<svg class="icon icon_scale"><use xlink:href="#double-arrow"/></svg></span></a></div></main><footer class="footer wrap pale"><p>&copy;&nbsp;<span class=year></span>&nbsp;Ikath Tech Blog</p><p class="attribution upcase">Designed by <a href="<no value>" target=_blank title="Linkedin Profile" rel=nonopener><no value></a></p></footer><script src=https://s-kaisei.github.io/Ikath-Tech-Blog/js/index.min.1a678c05b3d77bbd645a832d2c854f0e0728782ee0b9cc73940636c782bb1ec995125d2538c99ba876614f4e649bf837b9f43ff6bbd68a8d48a2a720e2dd3656.js></script><svg width="0" height="0" class="hidden"><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 699.428 699.428" id="copy"><path d="M502.714.0H240.428C194.178.0 153 42.425 153 87.429l-25.267.59c-46.228.0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249.0 87.428-42.424 87.428-87.428h21.857c46.25.0 87.429-42.424 87.429-87.428v-349.19L502.714.0zM459 655.715H131.143c-22.95.0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95.0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337.0 87.975.0 87.975.0 45.419 40.872 86.882 87.428 86.882H612v306zm-65.572-349.715c-23.277.0-43.714-42.293-43.714-64.981V44.348L612 174.857h-65.572zm-43.714 131.537H306c-12.065.0-21.857 9.77-21.857 21.835s9.792 21.835 21.857 21.835h196.714c12.065.0 21.857-9.771 21.857-21.835.0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065.0-21.857 9.77-21.857 21.834.0 12.066 9.792 21.836 21.857 21.836h196.714c12.065.0 21.857-9.77 21.857-21.836.0-12.064-9.792-21.834-21.857-21.834z"/></symbol><symbol viewBox="0 0 53 42" xmlns="http://www.w3.org/2000/svg" id="double-arrow"><path d="M.595 39.653a1.318 1.318.0 010-1.864L16.55 21.833a1.318 1.318.0 000-1.863L.595 4.014a1.318 1.318.0 010-1.863L2.125.62a1.318 1.318.0 011.864.0l19.35 19.349a1.318 1.318.0 010 1.863l-19.35 19.35a1.318 1.318.0 01-1.863.0zm29 0a1.318 1.318.0 010-1.864L45.55 21.833a1.318 1.318.0 000-1.863L29.595 4.014a1.318 1.318.0 010-1.863l1.53-1.53a1.318 1.318.0 011.864.0l19.35 19.349a1.318 1.318.0 010 1.863l-19.35 19.35a1.318 1.318.0 01-1.863.0z"/></symbol></svg></body></html>